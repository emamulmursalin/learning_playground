{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will implement word vectors. We will use both pretrained word vector and locally trained word vector. We will comapre both results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embedding = api.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('short', 0.8219379186630249),\n",
       " ('longer', 0.7952098250389099),\n",
       " ('once', 0.7616981267929077),\n",
       " ('still', 0.759249746799469),\n",
       " ('so', 0.7570570707321167),\n",
       " ('end', 0.7567450404167175),\n",
       " ('even', 0.7533906698226929),\n",
       " ('though', 0.7517069578170776),\n",
       " ('well', 0.7480059862136841),\n",
       " ('time', 0.7464157938957214)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check how good those pretrained embedding works\n",
    "wiki_embedding.most_similar('long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that most of the words are similar or close to the meaning of the inserted word.\n",
    "\n",
    "Now we will create our own vectorization model using gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                                    v2  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "  Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = pd.read_csv('spam.csv', encoding ='latin-1')\n",
    "message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                            email_text  \n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...  \n",
       "1                                                                        Ok lar... Joking wif u oni...  \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...  \n",
       "3                                                    U dun say so early hor... U c already then say...  \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Our dataset conatins columns which are having only NaN values so we need to get rid of it\n",
    "message.drop(labels=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace=True)\n",
    "\n",
    "#Also lets change the existing column name for better understanding\n",
    "message.columns= ['label', 'email_text']\n",
    "message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>email_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>[ok, lar, joking, wif, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...</td>\n",
       "      <td>[free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>[dun, say, so, early, hor, already, then, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives around here though</td>\n",
       "      <td>[nah, don, think, he, goes, to, usf, he, lives, around, here, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  \\\n",
       "0   ham   \n",
       "1   ham   \n",
       "2  spam   \n",
       "3   ham   \n",
       "4   ham   \n",
       "\n",
       "                                                                                            email_text  \\\n",
       "0  Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there g...   \n",
       "1                                                                        Ok lar... Joking wif u oni...   \n",
       "2  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive ...   \n",
       "3                                                    U dun say so early hor... U c already then say...   \n",
       "4                                        Nah I don't think he goes to usf, he lives around here though   \n",
       "\n",
       "                                                                                          cleaned_text  \n",
       "0  [go, until, jurong, point, crazy, available, only, in, bugis, great, world, la, buffet, cine, th...  \n",
       "1                                                                          [ok, lar, joking, wif, oni]  \n",
       "2  [free, entry, in, wkly, comp, to, win, fa, cup, final, tkts, st, may, text, fa, to, to, receive,...  \n",
       "3                                                       [dun, say, so, early, hor, already, then, say]  \n",
       "4                                [nah, don, think, he, goes, to, usf, he, lives, around, here, though]  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can manually tokenize and clean the data. But here we will use gensim library to take a shortcut\n",
    "message['cleaned_text'] = message['email_text'].apply(lambda x : gensim.utils.simple_preprocess(x))\n",
    "message.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now divide our training dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(message['cleaned_text'], message['label'],\n",
    "                                                   test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can create the vectorizing model\n",
    "w2v = gensim.models.Word2Vec(X_train, size = 100, window = 3, min_count = 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('he', 0.9997958540916443),\n",
       " ('off', 0.9997925758361816),\n",
       " ('just', 0.9997900128364563),\n",
       " ('its', 0.9997889399528503),\n",
       " ('here', 0.9997878670692444),\n",
       " ('not', 0.9997830390930176),\n",
       " ('today', 0.9997804164886475),\n",
       " ('well', 0.9997801780700684),\n",
       " ('in', 0.999778687953949),\n",
       " ('but', 0.9997777938842773)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('long')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the words are not even closer in meaning with the inserted word. So to get a better result it is necessary to train the model on a really large dataset.\n",
    "\n",
    "Now let's see how we can develop an ML model using the output of word to vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-6bb89ec2907e>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  w2v_vect = np.array([np.array([w2v.wv[i] for i in ls if i in w2v.wv.index2word]) for ls in X_test])\n"
     ]
    }
   ],
   "source": [
    "#Now we will create the vectorizing by using the model\n",
    "w2v_vect = np.array([np.array([w2v.wv[i] for i in ls if i in w2v.wv.index2word]) for ls in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The ML algorithm can not handle the variable number of input features. In our model, the number of words\n",
    "    #in the test emails are different. Moreover, not every words will have vector values. Because in the \n",
    "    #test set there may be some words which were not present at training set and eventually not vertorized\n",
    "w2v_vect_avg = []\n",
    "\n",
    "for vect in w2v_vect:\n",
    "    if len(vect)!=0:\n",
    "        w2v_vect_avg.append(vect.mean(axis=0))\n",
    "    else:\n",
    "        w2v_vect_avg.append(np.zeros(100))\n",
    "        \n",
    "#Here we have added the values column wise and then took the average. \n",
    "#So the input shape of numpy array for a 10 words email changes from (10,10) to list of 100 elements\n",
    "#It is worth remembering that in numpy, axis = 0 means column which is opposite of Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By averaging the values we loose important internal information. To avoid this, we can use a sentece level vectorization instead of word level. \n",
    "\n",
    "Like word2vec, there are also pretrained model for doc2vect but comperatively much less in numbers. We will implement here a custom trianed doc2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to tag the documents\n",
    "#For simplicity we will use the indexes as tagg\n",
    "\n",
    "tagged_doc = [gensim.models.doc2vec.TaggedDocument(v,[i]) for i, v in enumerate(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's train our model\n",
    "#It is similar to w2v; but here we have to pass list of taggs and size is replaced by vector_size\n",
    "d2v = gensim.models.Doc2Vec(tagged_doc, vector_size = 100,\n",
    "                           window = 3, min_count = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.47342366e-04,  1.08249690e-02,  7.10447261e-04,  1.45424148e-02,\n",
       "       -2.09554210e-02, -3.43396375e-03,  3.48304934e-03,  8.67612020e-04,\n",
       "        3.76065099e-03,  1.89243872e-02,  8.29740521e-03,  5.35160489e-03,\n",
       "       -1.60630494e-02, -1.69633850e-02,  4.13551723e-04,  9.96800140e-04,\n",
       "       -2.16301880e-03, -6.61700638e-03,  1.46541058e-03,  1.84242819e-02,\n",
       "       -1.90337782e-03,  4.36272565e-03,  9.96280555e-03,  1.20894169e-03,\n",
       "        7.59214256e-03, -4.60318197e-03, -4.94375871e-03,  4.74603893e-03,\n",
       "       -1.04742832e-02, -5.39830793e-03,  1.01084569e-02, -1.27405871e-03,\n",
       "       -1.61650195e-03, -7.56048551e-03,  2.44679209e-03, -9.18435544e-05,\n",
       "       -2.20834203e-02,  4.01854003e-03, -1.78542882e-02,  5.82707068e-03,\n",
       "       -1.60865462e-03, -1.11642096e-03, -1.13240108e-02,  6.38588890e-03,\n",
       "        4.55374038e-03, -1.58460217e-03, -1.25673162e-02, -1.07251685e-02,\n",
       "        6.58075931e-03, -5.39635657e-04, -9.59773362e-03, -1.48652866e-02,\n",
       "        9.92938294e-04, -5.91085525e-03, -5.36456425e-03,  6.05965918e-03,\n",
       "        3.37141869e-03, -8.95496225e-04,  6.27024099e-03, -9.13174916e-03,\n",
       "        1.89829920e-03,  1.30408779e-02,  1.75330546e-02, -1.39309792e-02,\n",
       "        1.10380573e-03,  4.09577088e-03, -3.62177845e-03,  4.12107911e-03,\n",
       "        2.90750642e-03,  1.22908596e-02, -4.97224927e-03, -2.29716487e-03,\n",
       "       -1.25589520e-02, -7.43412320e-03, -1.99321657e-02, -5.69960475e-03,\n",
       "        5.86579181e-03,  1.57054979e-03, -2.76848092e-03,  1.12246927e-02,\n",
       "        5.21015143e-03,  7.33349519e-03,  5.25427097e-03,  5.07285167e-03,\n",
       "       -2.53593619e-03, -1.02961641e-02, -5.08902548e-03, -9.80585907e-03,\n",
       "        1.07632931e-02, -8.10920537e-05,  1.05079180e-02,  9.53358971e-03,\n",
       "       -4.63647489e-03, -2.19874061e-03, -2.68757460e-03, -8.55804328e-03,\n",
       "        1.02158161e-02,  2.40816415e-04, -1.67783350e-02, -7.36157550e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To show the vector we have to pass a list of strings\n",
    "#In w2v we needed to pass the list of one string with w2v.wv['any_word'] command)\n",
    "#Here we have to use infer_vector\n",
    "d2v.infer_vector(['it', 'is', 'raining'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-bac39b26fdaf>:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  d2v.most_similar(['it', 'is', 'raining'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('going', 0.9996617436408997),\n",
       " ('if', 0.9996592998504639),\n",
       " ('can', 0.9996568560600281),\n",
       " ('one', 0.99965500831604),\n",
       " ('now', 0.9996535778045654),\n",
       " ('about', 0.9996533393859863),\n",
       " ('but', 0.9996504187583923),\n",
       " ('he', 0.9996503591537476),\n",
       " ('go', 0.9996497631072998),\n",
       " ('of', 0.9996475577354431)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just like w2v, we can call the most similar vectors\n",
    "d2v.most_similar(['it', 'is', 'raining'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unlike w2v, we do not have to take the average before feeding into the ML model\n",
    "\n",
    "d2v_vectors = [d2v.infer_vector(i) for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00069643,  0.02257366,  0.00070908,  0.0153123 , -0.0320973 ,\n",
       "       -0.01000468,  0.00416091, -0.00227025,  0.00497963,  0.02605775,\n",
       "        0.00804959,  0.01122246, -0.0256967 , -0.02589604,  0.0008933 ,\n",
       "       -0.00051676, -0.01105438, -0.01878889,  0.00686748,  0.02525457,\n",
       "        0.00111113,  0.00329549,  0.01572517,  0.00241998,  0.00296828,\n",
       "       -0.01601721, -0.01581485,  0.00788614, -0.01593765, -0.00413635,\n",
       "        0.02332717, -0.00236793,  0.00206217, -0.02156455, -0.00311842,\n",
       "        0.01127873, -0.04008573,  0.01191013, -0.03910189,  0.0102937 ,\n",
       "        0.00076298, -0.01141857, -0.02278094,  0.00951322,  0.01202042,\n",
       "       -0.01115231, -0.02073468, -0.00959048,  0.01501272, -0.00896481,\n",
       "       -0.01959412, -0.01697352,  0.00913172, -0.00905805, -0.00558412,\n",
       "        0.01323293,  0.00836749,  0.00334338,  0.00923952, -0.00659455,\n",
       "       -0.00039557,  0.02162655,  0.03645353, -0.01557582,  0.01276152,\n",
       "        0.01231494, -0.00451587,  0.01463225,  0.0012144 ,  0.02469604,\n",
       "       -0.0143704 , -0.00717343, -0.01504687, -0.00345248, -0.02492318,\n",
       "       -0.00424366,  0.00768649,  0.01420639, -0.0119553 ,  0.02955952,\n",
       "        0.0143793 ,  0.00539079,  0.01637173,  0.0128703 , -0.00763508,\n",
       "       -0.01649865, -0.00229164, -0.01670282,  0.01755852,  0.00944448,\n",
       "        0.01857233,  0.00901341, -0.00927294, -0.01197869, -0.00877108,\n",
       "       -0.0108473 ,  0.01127893, -0.00301048, -0.02760621, -0.00944637],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2v_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
